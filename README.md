![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![Hadoop](https://img.shields.io/badge/Hadoop-3.3.0-yellow)
![Status](https://img.shields.io/badge/status-stable-brightgreen)

# ğŸ¯ DÃ©tection de Clients Ã  Risque de Churn avec Hadoop MapReduce

## ğŸ“‹ ProblÃ©matique MÃ©tier

Dans les secteurs des tÃ©lÃ©communications, de la banque et du SaaS, identifier les clients susceptibles de partir (churn) est crucial pour la rÃ©tention. Ce projet analyse des logs d'usage massifs pour dÃ©tecter automatiquement les clients Ã  faible engagement, indicateur clÃ© du risque de churn.

### ğŸ¯ Objectifs

- **ScalabilitÃ©** : Traiter des tÃ©raoctets de logs d'usage quotidiens
- **Automatisation** : Scoring automatique des clients selon leur niveau de risque
- **Actionnable** : RÃ©sultats directement exploitables par les Ã©quipes marketing/customer success

## ğŸ—ï¸ Architecture

### Format des DonnÃ©es d'EntrÃ©e

```csv
user_id,timestamp,action,duration
U123,2025-09-01 10:10:10,login,0
U123,2025-09-01 10:15:00,watch_video,300
U124,2025-09-01 11:00:00,login,0
U124,2025-09-01 11:05:00,watch_video,20
```

### CritÃ¨res de DÃ©tection de Risque

Un client est considÃ©rÃ© **Ã  risque** si au moins un de ces critÃ¨res est vÃ©rifiÃ© :

- âš ï¸ **Moins de 5 actions** sur la pÃ©riode analysÃ©e
- â±ï¸ **DurÃ©e moyenne d'activitÃ© < 2 minutes**
- ğŸ­ **DiversitÃ© d'actions < 2 types** (ex: seulement login/logout)

### Pipeline MapReduce

#### ğŸ—ºï¸ **Mapper** (`mapper.py`)

- Lit chaque ligne de log
- Extrait : `user_id â†’ (1, duration, action)`
- Ã‰met les donnÃ©es structurÃ©es pour l'agrÃ©gation

#### ğŸ“Š **Reducer** (`reducer.py`)

- AgrÃ¨ge par `user_id`
- Calcule :
  - Nombre total d'actions
  - Temps total et temps moyen d'activitÃ©
  - DiversitÃ© des actions (nombre de types diffÃ©rents)
- Applique les rÃ¨gles mÃ©tier
- Ã‰met : `user_id â†’ OK|RISK`

## ğŸ“ Structure du Projet

```

hadoop-churn-detection/
â”‚
â”œâ”€â”€ mapper_reducer/
â”‚   â”œâ”€â”€ mapper.py              # Mapper Python pour extraction des donnÃ©es
â”‚   â””â”€â”€ reducer.py             # Reducer Python pour agrÃ©gation et scoring
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ generate_test_data.py  # GÃ©nÃ©rateur de donnÃ©es de test rÃ©alistes
â”‚   â”œâ”€â”€ sample_input.txt       # DonnÃ©es d'exemple gÃ©nÃ©rÃ©es
â”‚   â””â”€â”€ user_profiles_reference.txt  # Profils de rÃ©fÃ©rence pour validation
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_hadoop.sh          # Script d'exÃ©cution Hadoop Streaming
â”‚   â””â”€â”€ run_local_test.py      # Test local sans Hadoop
â”‚
â”œâ”€â”€ README.md                  # Cette documentation
â”œâ”€â”€ .gitignore                # Fichiers Ã  ignorer par Git
â”œâ”€â”€ local_test_results.txt    # RÃ©sultats du test en local
â””â”€â”€ Requirements.txt

```

## ğŸš€ Installation et Utilisation

### PrÃ©requis

- **Hadoop** configurÃ© avec HDFS
- **Python 3.6+**
- Variables d'environnement : `HADOOP_HOME`

### 1ï¸âƒ£ GÃ©nÃ©ration des DonnÃ©es de Test

```bash
cd data/
python3 generate_test_data.py
```

Cela gÃ©nÃ¨re :

- `sample_input.txt` : 700+ lignes de logs simulÃ©s
- `user_profiles_reference.txt` : Profils de rÃ©fÃ©rence pour validation

### 2ï¸âƒ£ Test Local (Sans Hadoop)

```bash
cd scripts/
python3 run_local_test.py
```

**Avantages du test local :**

- âœ… Validation rapide de la logique
- ğŸ› Debug facile des scripts
- ğŸ“Š Comparaison avec les profils de rÃ©fÃ©rence

### 3ï¸âƒ£ ExÃ©cution sur Hadoop

#### PrÃ©paration des donnÃ©es

```bash
# CrÃ©er les rÃ©pertoires HDFS
hdfs dfs -mkdir -p /user/input/churn_data
hdfs dfs -mkdir -p /user/output

# Copier les donnÃ©es
hdfs dfs -put data/sample_input.txt /user/input/churn_data/
```

#### Lancement du job

```bash
cd scripts/
chmod +x run_hadoop.sh
./run_hadoop.sh /user/input/churn_data /user/output/churn_results
```

#### RÃ©cupÃ©ration des rÃ©sultats

```bash
# Voir un aperÃ§u
hdfs dfs -cat /user/output/churn_results/part-00000 | head -20

# TÃ©lÃ©charger tous les rÃ©sultats
hdfs dfs -get /user/output/churn_results ./results
```

## ğŸ“Š Exemple de RÃ©sultats

```
U001    OK
U002    RISK
U003    OK
U004    RISK
U005    OK
```

### Statistiques Typiques

- **Clients analysÃ©s** : 50
- **Clients Ã  risque** : 10 (20%)
- **Clients OK** : 40 (80%)

## ğŸ”§ Configuration AvancÃ©e

### Personnalisation des Seuils

Modifiez les constantes dans `reducer.py` :

```python
MIN_ACTIONS = 5          # Minimum d'actions
MIN_AVG_DURATION = 2     # DurÃ©e moyenne minimale (minutes)
MIN_ACTION_DIVERSITY = 2 # Types d'actions minimum
```

### Profils d'Utilisateurs SimulÃ©s

Le gÃ©nÃ©rateur crÃ©e 3 profils rÃ©alistes :

| Profil             | % Users | Actions/jour | DurÃ©e moy. | DiversitÃ© |
| ------------------ | ------- | ------------ | ----------- | ---------- |
| **Active**   | 30%     | 8-15         | 30-600s     | Ã‰levÃ©e   |
| **Moderate** | 50%     | 3-8          | 10-300s     | Moyenne    |
| **At Risk**  | 20%     | 1-3          | 5-60s       | Faible     |

## ğŸ¯ Cas d'Usage MÃ©tier

### 1. **TÃ©lÃ©communications**

- Analyser les logs d'appels, SMS, data
- Identifier les clients rÃ©duisant leur usage

### 2. **Banque/Finance**

- Logs de transactions, connexions app mobile
- DÃ©tecter la baisse d'engagement

### 3. **SaaS/Streaming**

- Logs de connexions, visionnages, interactions
- PrÃ©dire les rÃ©siliations

## ğŸš€ Extensions Possibles

## ğŸ›£ï¸ Roadmap

- âœ… Version MapReduce fonctionnelle (MVP)
- âœ… GÃ©nÃ©rateur de donnÃ©es rÃ©alistes
- ğŸ”² IntÃ©gration PySpark
- ğŸ”² Pipeline temps rÃ©el (Kafka + Spark)
- ğŸ”² DÃ©ploiement DockerisÃ©

### ğŸ“ˆ **Scoring AvancÃ©**

- Remplacer les rÃ¨gles simples par du machine learning
- IntÃ©grer des features temporelles (tendances)

### âš¡ **Migration PySpark**

```python
# Exemple de logique Ã©quivalente en PySpark
df.groupBy("user_id").agg(
    count("action").alias("total_actions"),
    avg("duration").alias("avg_duration"),
    countDistinct("action").alias("action_diversity")
).withColumn("risk_status", 
    when((col("total_actions") < 5) | 
         (col("avg_duration") < 120) | 
         (col("action_diversity") < 2), "RISK")
    .otherwise("OK")
)
```

### ğŸ”„ **Pipeline Temps RÃ©el**

- IntÃ©gration avec Kafka/Kinesis
- Streaming avec Spark Structured Streaming

## ğŸ› DÃ©pannage

### Erreurs Communes

**1. `HADOOP_HOME not set`**

```bash
export HADOOP_HOME=/path/to/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

**2. `Permission denied` sur les scripts**

```bash
chmod +x mapper_reducer/*.py
chmod +x scripts/*.sh
```

**3. `JAR Hadoop Streaming non trouvÃ©`**

```bash
find $HADOOP_HOME -name "hadoop-streaming*.jar"
```

### Logs de Debug

```bash
# Voir les logs du job
yarn logs -applicationId <application_id>

# Logs HDFS
hdfs dfs -cat /user/output/churn_results/_logs/history/*
```

## ğŸ“š Ressources

- [Documentation Hadoop Streaming](https://hadoop.apache.org/docs/current/hadoop-streaming/HadoopStreaming.html)
- [Guide MapReduce](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
- [Bonnes pratiques Python pour Hadoop](https://www.cloudera.com/tutorials/getting-started-with-hadoop-tutorial.html)

---

**ğŸ’¡ Ce projet dÃ©montre comment transformer un problÃ¨me mÃ©tier complexe en solution scalable avec Hadoop MapReduce, applicable Ã  des tÃ©raoctets de donnÃ©es en production.**
