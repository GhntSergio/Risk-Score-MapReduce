#!/bin/bash

# Script d'ex√©cution du job Hadoop Streaming pour la d√©tection de churn
# Usage: ./run_hadoop.sh [input_path] [output_path]

set -e  # Arr√™ter en cas d'erreur

# Configuration par d√©faut
DEFAULT_INPUT="/user/input/churn_data"
DEFAULT_OUTPUT="/user/output/churn_results"
HADOOP_STREAMING_JAR="$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar"

# Param√®tres
INPUT_PATH=${1:-$DEFAULT_INPUT}
OUTPUT_PATH=${2:-$DEFAULT_OUTPUT}

# Chemins des scripts
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
MAPPER_PATH="$PROJECT_DIR/mapper_reducer/mapper.py"
REDUCER_PATH="$PROJECT_DIR/mapper_reducer/reducer.py"

echo "üöÄ Lancement du job Hadoop Streaming pour la d√©tection de churn"
echo "üìÅ R√©pertoire d'entr√©e: $INPUT_PATH"
echo "üìÅ R√©pertoire de sortie: $OUTPUT_PATH"
echo "üóÇÔ∏è Mapper: $MAPPER_PATH"
echo "üóÇÔ∏è Reducer: $REDUCER_PATH"

# V√©rifier que les fichiers existent
if [ ! -f "$MAPPER_PATH" ]; then
    echo "‚ùå Erreur: Mapper non trouv√© √† $MAPPER_PATH"
    exit 1
fi

if [ ! -f "$REDUCER_PATH" ]; then
    echo "‚ùå Erreur: Reducer non trouv√© √† $REDUCER_PATH"
    exit 1
fi

# V√©rifier que Hadoop est configur√©
if [ -z "$HADOOP_HOME" ]; then
    echo "‚ùå Erreur: HADOOP_HOME n'est pas d√©fini"
    exit 1
fi

# Trouver le JAR Hadoop Streaming
STREAMING_JAR=$(ls $HADOOP_STREAMING_JAR 2>/dev/null | head -1)
if [ -z "$STREAMING_JAR" ]; then
    echo "‚ùå Erreur: JAR Hadoop Streaming non trouv√© dans $HADOOP_STREAMING_JAR"
    exit 1
fi

echo "üì¶ JAR Streaming: $STREAMING_JAR"

# Supprimer le r√©pertoire de sortie s'il existe
echo "üßπ Nettoyage du r√©pertoire de sortie..."
hdfs dfs -rm -r -f "$OUTPUT_PATH"

# Rendre les scripts ex√©cutables
chmod +x "$MAPPER_PATH"
chmod +x "$REDUCER_PATH"

echo "‚ö° Ex√©cution du job MapReduce..."

# Lancer le job Hadoop Streaming
hadoop jar "$STREAMING_JAR" \
    -files "$MAPPER_PATH","$REDUCER_PATH" \
    -mapper "python3 mapper.py" \
    -reducer "python3 reducer.py" \
    -input "$INPUT_PATH" \
    -output "$OUTPUT_PATH" \
    -cmdenv PYTHONIOENCODING=utf-8

# V√©rifier le succ√®s
if [ $? -eq 0 ]; then
    echo "‚úÖ Job termin√© avec succ√®s!"
    echo "üìä R√©sultats disponibles dans: $OUTPUT_PATH"
    
    echo "üîç Aper√ßu des r√©sultats:"
    hdfs dfs -cat "$OUTPUT_PATH/part-00000" | head -20
    
    echo ""
    echo "üìà Statistiques:"
    echo "Nombre total de clients analys√©s:"
    hdfs dfs -cat "$OUTPUT_PATH/part-*" | wc -l
    
    echo "Clients √† risque (RISK):"
    hdfs dfs -cat "$OUTPUT_PATH/part-*" | grep -c "RISK" || echo "0"
    
    echo "Clients OK:"
    hdfs dfs -cat "$OUTPUT_PATH/part-*" | grep -c "OK" || echo "0"
    
else
    echo "‚ùå √âchec du job MapReduce"
    exit 1
fi

echo ""
echo "üéØ Pour r√©cup√©rer tous les r√©sultats:"
echo "hdfs dfs -get $OUTPUT_PATH ./results"
echo ""
echo "üîÑ Pour relancer avec d'autres param√®tres:"
echo "$0 <chemin_entr√©e> <chemin_sortie>"