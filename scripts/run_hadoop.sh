#!/bin/bash
# --------------------------------------------------------
# Script d'ex√©cution du job Hadoop Streaming (d√©tection de churn)
# Usage: ./run_hadoop.sh [input_path_hdfs] [output_path_hdfs]
# --------------------------------------------------------

set -e  # Arr√™t en cas d'erreur

# Configuration par d√©faut
DEFAULT_INPUT="/user/input/churn_data"
DEFAULT_OUTPUT="/user/output/churn_results"
HADOOP_STREAMING_JAR="$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.4.1.jar"

# Param√®tres (priorit√© aux arguments pass√©s au script)
INPUT_PATH=${1:-$DEFAULT_INPUT}
OUTPUT_PATH=${2:-$DEFAULT_OUTPUT}

# R√©pertoires des scripts (mont√©s depuis l‚Äôh√¥te dans le conteneur)
SCRIPT_DIR="/scripts"
MAPPER_PATH="$SCRIPT_DIR/mapper.py"
REDUCER_PATH="$SCRIPT_DIR/reducer.py"

echo "üöÄ Lancement du job Hadoop Streaming"
echo "üìÅ Input HDFS: $INPUT_PATH"
echo "üìÅ Output HDFS: $OUTPUT_PATH"
echo "üóÇÔ∏è Mapper: $MAPPER_PATH"
echo "üóÇÔ∏è Reducer: $REDUCER_PATH"

# V√©rification des fichiers
[ -f "$MAPPER_PATH" ] || { echo "‚ùå Mapper introuvable: $MAPPER_PATH"; exit 1; }
[ -f "$REDUCER_PATH" ] || { echo "‚ùå Reducer introuvable: $REDUCER_PATH"; exit 1; }

# V√©rification Hadoop
[ -n "$HADOOP_HOME" ] || { echo "‚ùå Erreur: HADOOP_HOME non d√©fini"; exit 1; }
[ -f "$HADOOP_STREAMING_JAR" ] || { echo "‚ùå Erreur: jar Hadoop Streaming introuvable"; exit 1; }

echo "üì¶ JAR Streaming: $HADOOP_STREAMING_JAR"

# Nettoyage sortie
echo "üßπ Suppression de l‚Äôancienne sortie (si existe)..."
hdfs dfs -rm -r -f -skipTrash "$OUTPUT_PATH" || true

# Rendre ex√©cutables
chmod +x "$MAPPER_PATH" "$REDUCER_PATH"

echo "‚ö° Ex√©cution du job..."

# Lancement du job Hadoop Streaming
hadoop jar "$HADOOP_STREAMING_JAR" \
    -files "$MAPPER_PATH","$REDUCER_PATH" \
    -mapper "./mapper.py" \
    -reducer "./reducer.py" \
    -input "$INPUT_PATH" \
    -output "$OUTPUT_PATH" \
    -cmdenv PYTHONIOENCODING=utf-8

# V√©rification du succ√®s
if [ $? -eq 0 ]; then
    echo "‚úÖ Job termin√© avec succ√®s"
    echo "üìä R√©sultats (aper√ßu 20 lignes) :"
    hdfs dfs -cat "$OUTPUT_PATH/part-00000" | head -20

    echo ""
    echo "üìà Statistiques globales :"
    hdfs dfs -cat "$OUTPUT_PATH/part-*" | cut -f2 | sort | uniq -c
else
    echo "‚ùå √âchec du job MapReduce"
    exit 1
fi

echo ""
echo "üéØ Pour rapatrier les r√©sultats localement :"
echo "hdfs dfs -get $OUTPUT_PATH ./results"
